{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Image Classification Inference from Hugging Face Model\n",
    "\n",
    "This notebook demonstrates how to run image inference on a Hugging Face model that determines if an image is male or female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "First we must install the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers torch pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "Then we can load [the model](https://huggingface.co/dima806/fairface_gender_image_detection) from Hugging Face. We will use the `AutoModelForImageClassification` class to load the model since we want to perform image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageClassification\n",
    "\n",
    "model_name = \"dima806/fairface_gender_image_detection\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image\n",
    "\n",
    "Next we can load the image from the file system into [Pillow](https://python-pillow.org). We then pass the image to the processor to prepare it for inference. The `return_tensors` parameter is set to `pt` to return PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = \"image.jpeg\" # Change this to the path of your image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Inference\n",
    "\n",
    "Finally we can perform inference on the image by passing it to the model, and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(**inputs)\n",
    "\n",
    "predictions = outputs.logits.argmax(dim=-1)\n",
    "model_labels = model.config.id2label # A dictionary where the keys are the model output labels and the values are the human-readable labels. For example, {0: \"Female\", 1: \"Male\"}\n",
    "predicted_label = model_labels[predictions.item()] # We can then use the predicted label to get the human-readable label\n",
    "print(predicted_label) # Print human readable label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
